{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GMM-UBM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-77QZwTfIvo3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9ef7553b-c3d8-4160-c602-a6ec8bb9ca1e"
      },
      "source": [
        "pip install python_speech_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.6/dist-packages (0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVujVbqyP1xy",
        "colab_type": "text"
      },
      "source": [
        "Remove Silence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9pzb9xNPyI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def remove_silence(audio):\n",
        "  audio_m=[]\n",
        "  for i in range(len(audio)):\n",
        "    if (abs(audio[i])>10):\n",
        "      audio_m.append(audio[i])\n",
        "  audio_m = np.asarray(audio_m)\n",
        "  return audio_m\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVPl8XGQSJcn",
        "colab_type": "text"
      },
      "source": [
        "Extract_Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbdthUlBHt8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from python_speech_features import mfcc as MFCC\n",
        "from python_speech_features import delta\n",
        "from sklearn import preprocessing\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "\n",
        "def extract_featrue(audio,fs):\n",
        "    mfcc_feature = MFCC(audio, fs,)\n",
        "    mfcc = preprocessing.scale(mfcc_feature)\n",
        "    mfcc_delta = delta(mfcc_feature, 2)\n",
        "    mfcc_double_delta = delta(mfcc_delta, 2)\n",
        "    mfcc_final = np.hstack([mfcc, mfcc_delta, mfcc_double_delta])\n",
        "    return mfcc_final\n",
        "\n",
        "\n",
        "def get_feature(path,task):\n",
        "    file_paths = []\n",
        "    # get all  wav file\n",
        "    for root, sub, files in os.walk(path):\n",
        "        files = [f for f in files if f.endswith(\".WAV\")]\n",
        "        speaker_file_paths = []\n",
        "        for file in files:\n",
        "            speaker_file_paths.append(os.path.join(root, file))\n",
        "        if speaker_file_paths != []:\n",
        "            file_paths.append(speaker_file_paths)\n",
        "\n",
        "    output_path = 'output/op'\n",
        "    fs=16000\n",
        "    if task == 'train':\n",
        "      Feature = np.array([])\n",
        "      for speaker_file in file_paths:\n",
        "          for file in speaker_file:\n",
        "              [fs, audio] = wavfile.read(file)\n",
        "              audio = remove_silence(audio)\n",
        "              vector = extract_featrue(audio, fs)\n",
        "              if Feature.size == 0:\n",
        "                  Feature = vector\n",
        "              else:\n",
        "                  Feature = np.vstack([Feature, vector])\n",
        "      return Feature\n",
        "    else:\n",
        "      Feature = []\n",
        "      for speaker_file in file_paths:\n",
        "          for file in speaker_file:\n",
        "              print(speaker_file)\n",
        "              print(file)\n",
        "              [fs, audio] = wavfile.read(file)\n",
        "              audio = remove_silence(audio)\n",
        "              vector = extract_featrue(audio, fs)\n",
        "              Feature.append(vector)\n",
        "      return Feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB5O5T6MSDFo",
        "colab_type": "text"
      },
      "source": [
        "Reading Data and Building UBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLeTYPp839TK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import copy\n",
        "import math\n",
        "import seaborn as sns;sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ubm_guassian_no = 64\n",
        "feature_dim = 39\n",
        "train_path = 'drive/My Drive/Colab Notebooks/SIP Project/TIMIT_modified/TRAIN/Train_data'\n",
        "Feature = get_feature(train_path,'test')\n",
        "Feature= np.vstack(Feature)\n",
        "ubm = GaussianMixture(n_components=ubm_guassian_no,covariance_type='diag',max_iter=100)\n",
        "ubm.fit(Feature)\n",
        "\n",
        "speaker_path = 'drive/My Drive/Colab Notebooks/SIP Project/TIMIT_modified/TRAIN/target'\n",
        "spk_feature = get_feature(speaker_path,'test')\n",
        "n_target_spk = len(spk_feature)\n",
        "print(f'Number of taret speaker :{n_target_spk}')\n",
        "test_path = 'drive/My Drive/Colab Notebooks/SIP Project/TIMIT_modified/TRAIN/test'\n",
        "test_feature = get_feature(test_path,'test')\n",
        "n_test_spk = len(test_feature)\n",
        "print(f'Number of test speaker :{n_test_spk}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "189cZSwnD0q6",
        "colab_type": "text"
      },
      "source": [
        "Building Speaker specific Model and verifying test speaker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1taixQXjRo1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FP=0\n",
        "TP=0\n",
        "FN=0\n",
        "TN=0\n",
        "\n",
        "ratio_mat = np.zeros((n_target_spk,n_target_spk))\n",
        "\n",
        "for k in range(n_target_spk):\n",
        "  spk_model = GaussianMixture(n_components=ubm_guassian_no,covariance_type='diag')\n",
        "  spk_model = copy.deepcopy(ubm)\n",
        "  T = len(spk_feature[k])\n",
        "  Pr = spk_model.predict_proba(spk_feature[k])\n",
        "  n = np.zeros(ubm_guassian_no)\n",
        "  m = np.zeros((ubm_guassian_no,feature_dim))\n",
        "  v = np.zeros((ubm_guassian_no,feature_dim))\n",
        "\n",
        "  for i in range(len(spk_feature[k])):\n",
        "      n = n + Pr[i]\n",
        "      for j in range(len(Pr[i])):\n",
        "          m[j] = m[j] + Pr[i][j]*spk_feature[k][i]\n",
        "          v[j] = v[j] + Pr[i][j]*np.square(spk_feature[k][i])\n",
        "\n",
        "  for i in range(ubm_guassian_no):\n",
        "      m[i] = m[i]/n[i]\n",
        "      v[i] = v[i]/n[i]\n",
        "\n",
        "  alpha = n/(n+16)\n",
        "\n",
        "  spk_model.weights_ = ((alpha*n/T) + ((1-alpha)*spk_model.weights_))\n",
        "  spk_model.weights_ = spk_model.weights_/np.sum(spk_model.weights_)\n",
        "  for i in range(ubm_guassian_no):\n",
        "      spk_model.means_[i] = alpha[i]*m[i] + (1-alpha[i])*spk_model.means_[i]\n",
        "      spk_model.covariances_[i] = alpha[i]*v[i] + (1-alpha[i])*(spk_model.covariances_[i] + np.square(spk_model.means_[i])) - np.square(spk_model.means_[i])\n",
        "\n",
        "  #Test\n",
        "  for i in range(len(test_feature)):\n",
        "    lp_ubm = np.exp(ubm.score_samples(test_feature[i]))\n",
        "    lp_spk = np.exp(spk_model.score_samples(test_feature[i]))\n",
        "    lp_ubm = np.sum(lp_ubm)\n",
        "    lp_spk = np.sum(lp_spk)\n",
        "    ratio = lp_spk/lp_ubm\n",
        "    ratio_mat[i//5,k]+=ratio\n",
        "\n",
        "    if(k==(i//5)):\n",
        "      if (ratio > 1):\n",
        "        TP+=1\n",
        "      else:\n",
        "        FN+=1\n",
        "    else:\n",
        "      if (ratio > 1):\n",
        "        FP+=1\n",
        "      else:\n",
        "        TN+=1\n",
        "\n",
        "\n",
        "FAR = FP/(n_test_spk*n_target_spk)\n",
        "FRR = FN/(n_test_spk*n_target_spk)\n",
        "\n",
        "print(f'TP:{TP}')\n",
        "print(f'FP:{FP}')\n",
        "print(f'FN:{FN}')\n",
        "print(f'TN:{TN}')\n",
        "print(f'FAR:{FAR}')\n",
        "print(f'FRR:{FRR}')\n",
        "\n",
        "#Confusion matrix\n",
        "cnf_mat = np.zeros((2,2))\n",
        "cnf_mat[0,0]=TP\n",
        "cnf_mat[0,1]=FP\n",
        "cnf_mat[1,0]=FN\n",
        "cnf_mat[1,1]=TN\n",
        "\n",
        "ratio_mat = ratio_mat/5\n",
        "sns.heatmap(ratio_mat,cmap=\"YlGnBu\",annot=False,xticklabels=['1','2','3','4','5','6','7','8','9','10'],yticklabels=['1','2','3','4','5','6','7','8','9','10'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}