{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "i_vector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7HSVhrRmCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a70838e9-0783-4068-eb88-d8e8fd7775bb"
      },
      "source": [
        "pip install python_speech_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.6/dist-packages (0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D54E2303IJsR",
        "colab_type": "text"
      },
      "source": [
        "Extract Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKspOmtqXDvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from python_speech_features import mfcc as MFCC\n",
        "from python_speech_features import delta\n",
        "from sklearn import preprocessing\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "\n",
        "def extract_featrue(audio,fs):\n",
        "    mfcc_feature = MFCC(audio, fs)\n",
        "    mfcc = preprocessing.scale(mfcc_feature)\n",
        "    mfcc_delta = delta(mfcc_feature, 2)\n",
        "    mfcc_double_delta = delta(mfcc_delta, 2)\n",
        "    mfcc_final = np.hstack([mfcc, mfcc_delta, mfcc_double_delta])\n",
        "    return mfcc_final\n",
        "\n",
        "\n",
        "def get_feature(path,task):\n",
        "    file_paths = []\n",
        "    # get all  wav file\n",
        "    for root, sub, files in os.walk(path):\n",
        "        files = [f for f in files if f.endswith(\".WAV\")]\n",
        "        speaker_file_paths = []\n",
        "        for file in files:\n",
        "            speaker_file_paths.append(os.path.join(root, file))\n",
        "        if speaker_file_paths != []:\n",
        "            file_paths.append(speaker_file_paths)\n",
        "\n",
        "    output_path = 'output/op'\n",
        "    fs=16000\n",
        "    if task == 'train':\n",
        "      Feature = np.array([])\n",
        "      for speaker_file in file_paths:\n",
        "          for file in speaker_file:\n",
        "              [fs, audio] = wavfile.read(file)\n",
        "              audio = remove_silence(audio)\n",
        "              vector = extract_featrue(audio, fs)\n",
        "              if Feature.size == 0:\n",
        "                  Feature = vector\n",
        "              else:\n",
        "                  Feature = np.vstack([Feature, vector])\n",
        "      return Feature\n",
        "    else:\n",
        "      Feature = []\n",
        "      for speaker_file in file_paths:\n",
        "          for file in speaker_file:\n",
        "              [fs, audio] = wavfile.read(file)\n",
        "              audio = remove_silence(audio)\n",
        "              vector = extract_featrue(audio, fs)\n",
        "              Feature.append(vector)\n",
        "      return Feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEulofnvIPTk",
        "colab_type": "text"
      },
      "source": [
        "Remove Silence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3XJh46wRzR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def remove_silence(audio):\n",
        "  audio_m=[]\n",
        "  for i in range(len(audio)):\n",
        "    if (abs(audio[i])>10):\n",
        "      audio_m.append(audio[i])\n",
        "  audio_m = np.asarray(audio_m)\n",
        "  return audio_m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-GuYQVgIWuR",
        "colab_type": "text"
      },
      "source": [
        "Get BW statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTb2BeWuiVTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_BW_stat(ubm,spk_feature,n_feature,n_clusters,n_utterance):\n",
        "  N_c_list = []\n",
        "  N_list = []\n",
        "  S_list = []\n",
        "  F_list = []\n",
        "\n",
        "  for u in range(n_utterance):\n",
        "    utterance= spk_feature[u]\n",
        "    posterior = ubm.predict_proba(utterance)\n",
        "    n_c = posterior.sum(axis=0)\n",
        "    N_c_list.append(n_c)\n",
        "    f = np.zeros((n_feature,n_clusters))\n",
        "    s = np.zeros((n_feature,n_clusters))\n",
        "    for i in range(len(posterior)):\n",
        "        for j in range(n_clusters):\n",
        "          x = utterance[i]-ubm.means_[j]\n",
        "          x = x.reshape(-1,1)\n",
        "          f[:,j] += (utterance[i]-ubm.means_[j])*posterior[i,j]\n",
        "          s[:,j] += np.diag(posterior[i,j]*np.dot(x,x.T))\n",
        "    \n",
        "    for i in range(n_clusters):\n",
        "      if i==0:\n",
        "        N = np.ones(n_feature)*n_c[i]\n",
        "        F = f[:,i]\n",
        "        S = s[:,i]\n",
        "        m = ubm.means_[i]\n",
        "        cov = ubm.covariances_[i]\n",
        "      else:\n",
        "        N = np.hstack([N,np.ones(n_feature)*n_c[i]])\n",
        "        F = np.hstack([F,f[:,i]])\n",
        "        S = np.hstack([S,s[:,i]])\n",
        "        m = np.hstack([m,ubm.means_[i]])\n",
        "        cov = np.hstack([cov,ubm.covariances_[i]])\n",
        "        \n",
        "    F_list.append(F)\n",
        "    N = np.diag(N)\n",
        "    N_list.append(N)\n",
        "    S = np.diag(S)\n",
        "    S_list.append(S)\n",
        "  cov = np.diag(cov)\n",
        "  return N_list,F_list,S_list,N_c_list,cov"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpANePwmInov",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNjqr573eot9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import copy\n",
        "import math\n",
        "import seaborn as sns;sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import multi_dot\n",
        "from scipy.linalg import eig\n",
        "import seaborn as sns;sns.set()\n",
        "\n",
        "n_feature = 39\n",
        "n_clusters = 64\n",
        "R = 100\n",
        "n_iteration = 5\n",
        "print(\"Generating UBM\")\n",
        "train_path = 'drive/My Drive/Colab Notebooks/SIP Project/TIMIT_modified/TRAIN/Train_data'\n",
        "spk_feature = get_feature(train_path,'test')\n",
        "feature = np.vstack(spk_feature)\n",
        "ubm = GaussianMixture(n_components=n_clusters,covariance_type='diag',max_iter=100)\n",
        "ubm.fit(feature)\n",
        "del feature\n",
        "n_utterance = len(spk_feature)\n",
        "n_spk = 10\n",
        "\n",
        "#Get BW Statistics\n",
        "N_list,F_list,S_list,N_c_list,cov = get_BW_stat(ubm,spk_feature,n_feature,n_clusters,n_utterance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaDys-zNIynn",
        "colab_type": "text"
      },
      "source": [
        "EM algorithm to get T and Sigma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaxZVOgXR1-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T = np.zeros((n_clusters*n_feature,R))\n",
        "for i in range(n_clusters):\n",
        "  T[i,:] = np.random.uniform(-0.1*cov[i,i],0.1*cov[i,i],R)                                                        \n",
        "\n",
        "print(\"Starting EM iterations\")\n",
        "for itr in range(n_iteration):\n",
        "  #E - step\n",
        "  print(f'Iteration :{itr}')\n",
        "  E_wwT_list = []\n",
        "  E_w_list = []\n",
        "  for u in range(len(spk_feature)):\n",
        "    inv_cov = np.linalg.inv(cov)\n",
        "    l = np.eye(R) + multi_dot([T.T,inv_cov,N_list[u],T])\n",
        "    inv_l = np.linalg.inv(l)\n",
        "    E_w = multi_dot([inv_l,T.T,inv_cov,F_list[u]])\n",
        "    E_w_list.append(E_w)\n",
        "    cov_w = inv_l \n",
        "    E_wwT = cov_w + np.dot(E_w,E_w.T)\n",
        "    E_wwT_list.append(E_wwT)\n",
        "    \n",
        "  # M - step\n",
        "  C_m = np.zeros((n_clusters*n_feature,R))\n",
        "  N_m = np.zeros((n_clusters*n_feature,n_clusters*n_feature))\n",
        "  A_m = np.zeros((n_clusters,R,R))\n",
        "  S_m = np.zeros((n_clusters*n_feature,n_clusters*n_feature)) \n",
        "  for u in range(n_utterance):\n",
        "    C_m += np.dot(F_list[u].reshape(-1,1),E_w_list[u].reshape(1,-1))\n",
        "    N_m += N_list[u]\n",
        "    for i in range(n_clusters):\n",
        "      A_m[i] += N_c_list[u][i]*E_wwT_list[u]\n",
        "    S_m += S_list[u]\n",
        "\n",
        "  cov = np.dot(np.linalg.inv(N_m),S_m-np.diag(np.diag(np.dot(C_m,T.T))))\n",
        "\n",
        "  for c in range(n_clusters):\n",
        "    for f in range(n_feature):\n",
        "      i = c*n_feature + f \n",
        "      T[i,:] = np.dot(C_m[i,:],np.linalg.inv(A_m[c])) \n",
        "\n",
        "\n",
        "inv_cov = np.linalg.inv(cov)\n",
        "w_list = []\n",
        "ws_list = []\n",
        "ws_mean = []\n",
        "\n",
        "#For projection matrix A\n",
        "for u in range(n_utterance):\n",
        "  N_list,F_list,_,_,_ = get_BW_stat(ubm,[spk_feature[u]],n_feature,n_clusters,n_utterance=1)\n",
        "  l = np.eye(R) + multi_dot([T.T,inv_cov,N_list[0],T])\n",
        "  inv_l = np.linalg.inv(l)\n",
        "  w_list.append(multi_dot([inv_l,T.T,inv_cov,F_list[0]]))\n",
        "  ws_list.append(w_list[u])\n",
        "  if (u+1)%(n_utterance/n_spk)==0 :\n",
        "    ws_mean.append(np.mean(np.asarray(ws_list),axis=0))\n",
        "    ws_list = []\n",
        "\n",
        "w_mean = np.mean(np.asarray(w_list),axis=0)\n",
        "sb = np.zeros((R,R))\n",
        "sw = np.zeros((R,R))\n",
        "\n",
        "for s in range(n_spk):\n",
        "  sb += np.dot((ws_mean[s]-w_mean).reshape(-1,1),(ws_mean[s]-w_mean).reshape(1,-1))\n",
        "  sw_temp = np.zeros((R,R))\n",
        "  for n in range(int(n_utterance/n_spk)):\n",
        "    i = int(s*(n_utterance/n_spk)+n)\n",
        "    sw_temp += np.dot((w_list[i]-ws_mean[s]).reshape(-1,1),(w_list[i]-ws_mean[s]).reshape(1,-1))\n",
        "  sw += np.divide(sw_temp,(n_utterance/n_spk))\n",
        "eigen,A = eig(sb,sw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0BIojEZz7y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TP = 0\n",
        "FP = 0\n",
        "FN = 0\n",
        "TN = 0\n",
        "score_mat = np.zeros((n_spk,n_spk))\n",
        "w_target_list=[]\n",
        "#For target utterance\n",
        "target_spk_path = 'drive/My Drive/Colab Notebooks/SIP Project/TIMIT_modified/TRAIN/target'\n",
        "target_spk_feature = get_feature(target_spk_path,'test')\n",
        "n_target_spk = len(target_spk_feature)\n",
        "for i in range(len(target_spk_feature )):\n",
        "  N_list,F_list,_,_,_ = get_BW_stat(ubm,[target_spk_feature[i]],n_feature,n_clusters,n_utterance=1)\n",
        "  l = np.eye(R) + multi_dot([T.T,inv_cov,N_list[0],T])\n",
        "  inv_l = np.linalg.inv(l)\n",
        "  w_target_list.append(multi_dot([inv_l,T.T,inv_cov,F_list[0]]))\n",
        "del target_spk_feature\n",
        "\n",
        "\n",
        "#For test utterance\n",
        "test_spk_path = 'drive/My Drive/Colab Notebooks/SIP Project/TIMIT_modified/TRAIN/test'\n",
        "test_spk_feature = get_feature(test_spk_path,'test')\n",
        "n_test_spk = len(test_spk_feature)\n",
        "for j in range(n_spk):\n",
        "  for i in range(len(test_spk_feature)):\n",
        "    N_list,F_list,_,_,_ = get_BW_stat(ubm,[test_spk_feature[i]],n_feature,n_clusters,n_utterance=1)\n",
        "    l = np.eye(R) + multi_dot([T.T,inv_cov,N_list[0],T])\n",
        "    inv_l = np.linalg.inv(l)\n",
        "    w_test = multi_dot([inv_l,T.T,inv_cov,F_list[0]])\n",
        "    #Cosine score\n",
        "    #score = np.dot(w_target_list[j],w_test)/(np.linalg.norm(w_target_list[j])*np.linalg.norm(w_test)\n",
        "    #Cosine score with LDA\n",
        "    score = np.dot(np.dot(A.T,w_target_list[j]),np.dot(A.T,w_test))/(np.linalg.norm(np.dot(A.T,w_target_list[j]))*np.linalg.norm(np.dot(A.T,w_test)))\n",
        "    #norm = np.linalg.norm(np.dot(A.T,w_target_list[j])-np.dot(A.T,w_test))\n",
        "    #Power Kernel\n",
        "    #score = norm**5\n",
        "    #Multiquadric Kernel\n",
        "    #score = np.math.sqrt(norm**2+1)-1\n",
        "    #Rational quadratic Kernel\n",
        "    #score = 1-((norm**2+1)/norm**2)\n",
        "    score_mat[i//5,j] += score\n",
        "    if (j==(i//5)):      \n",
        "      if(score>0.6):\n",
        "        TP+=1\n",
        "      else:\n",
        "        FN+=1\n",
        "    else:\n",
        "      if(score<0.6):\n",
        "        TN+=1\n",
        "      else:\n",
        "        FP+=1\n",
        "\n",
        "FAR = FP/(n_test_spk*n_target_spk)\n",
        "FRR = FN/(n_test_spk*n_target_spk)\n",
        "\n",
        "print(f'TP:{TP}')\n",
        "print(f'FP:{FP}')\n",
        "print(f'FN:{FN}')\n",
        "print(f'TN:{TN}')\n",
        "print(f'FAR:{FAR}')\n",
        "print(f'FRR:{FRR}')\n",
        "\n",
        "cnf_mat = np.zeros((2,2))\n",
        "cnf_mat[0,0]=TP\n",
        "cnf_mat[0,1]=FP\n",
        "cnf_mat[1,0]=FN\n",
        "cnf_mat[1,1]=TN\n",
        "\n",
        "score_mat = score_mat/5\n",
        "sns.heatmap(score_mat,cmap=\"YlGnBu\",annot=False,xticklabels=['1','2','3','4','5','6','7','8','9','10'],yticklabels=['1','2','3','4','5','6','7','8','9','10'])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}